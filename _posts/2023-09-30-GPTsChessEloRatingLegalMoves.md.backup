---
layout: post
title:  "Debunking the Chessboard: Confronting GPTs Against Chess Engines to Estimate Elo Ratings and Assess Legal Move Abilities"
date:   2023-09-30 011:54:29 +0200
tags: [ChatGPT, LLM, generative AI, variability, programming]
---

Can GPTs like ChatGPT-4 play legal moves and finish chess games? What is the actual Elo rating of GPTs? There have been some hypes, subjective assessment, and buzz lately from "GPT is capable of beating 99% of players?" to "GPT plays lots of illegal moves" to "here is a magic prompt with Magnus Carlsen in the headers". There are solid anecdotes here and there, with counter-examples showing impressive failures or magnified stories on how GPTs can play chess well. I've resisted for a long time, but I've decided to do it seriously! I have synthesized hundreds of games with different variants of GPT, different prompt strategies, against different chess engines (with various skills). This post is here to document the variability space of experiments I have explored so far... and the underlying insights and results. The tldr; is that `gpt-3.5-turbo-instruct` operates around 1750 Elo and is capable of playing end-to-end legal moves, even when the game starts with strange openings. ChatGPT-3.5-turbo and ChatGPT-4, however, are much more brittle and .  


## GPTs and Chess: the 2020 prehistoric days 

If you read this blog or follow me on Twitter, you know I have been interested for a while about generative AI technologies and chess. 
Some examples: 
 * 
 * 
 * 

I have compiled a long list of things to explore... I've resisted for a long time, but I've decided to do it more seriously!



![](/assets/...png)

 







 














