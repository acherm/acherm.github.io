---
layout: post
title:  "VaMoS 2024"
date:   2024-02-11 011:54:29 +0200
tags: [dissemination, variability, variants, configuration, conference, vamos] 
---

I'm back from [VaMoS 2024](https://vamos2024.inf.unibe.ch/) that has been held in Bern (Switzerland). As in [2020](https://blog.mathieuacher.com/VaMoS2020/) (and actually as in 2007, 2008, ..., 2023) a great conference about software variability, variants and configurations. 
Here is small report and a few thoughts about the event, that (teasing!) will be organized in Rennes (France) in 2025.

I started VaMoS with [MODEVAR](https://modevar.github.io/) workshop the day before, around 30 attendees. 
I gave a keynote "24 Reasons Why Variability Models Are Not Yet Universal" aka (24RWVMANYU). 
The slides: https://github.com/acherm/24RWVMANYU-VaMoS-MODEVAR/blob/main/vamos2024.md (Markdown content) or in PDF on slideshare: https://www.slideshare.net/slideshows/24-reasons-why-variability-models-are-not-yet-universal-24rwvmanyu/266166318 are available online. 
Variability models (e.g., feature models) are widely used in software engineering practice and research, but there are some "silent" open problems or frustrations that I wanted to share. 
The list is opinionated, incomplete, and was mainly here to foster some discussions. 
I used for the first time `reveal.js` to have the content in more readable and reusable format. Originally I wanted to generate the slides out of a specification of the list, and I found that Markdown could fit the purpose. It also forces me to not use many pictures or fancy diagrams. 
To add fun to the fun, I've randomized the order of the 24 reasons (and slides). At some points, I click on a link of the slides, which has the effect of randomize again the slides. Ouch! 
Anyway, I had a lot of fun and there were many reactions, remarks, questions, etc. 
The rest of the day was brainstorming about eg the UVL language https://github.com/Universal-Variability-Language/ an ongoing initiative to provide support for feature models. Web support, LSP, dataset sharing, APIs: It's going into the right direction.
Thanks to Jessie Galasso and Chico Sundermann for the invitation, and the perfect organization of MODEVAR! 

Then VaMoS really started with an industrial keynote of Slawomir Duszynski, product line architect at Bosch.
Some stunning numbers about complexity and variability: A motor control software at Bosch is ~120,000 variable components, ~10,000 long-living products, 300 interacting components with millions LOC in total, and 100+ feature models. 
When I started my PhD in 2008, having multiple feature models was not so obvious. But yes, variability is deep, spanning different layers and inter-connected systems. 
The speaker challenged reverse engineering and extractive approaches of variability. I couldn't agree more, it was on my list of 24 ;) and I've already written about eg in this blog https://blog.mathieuacher.com/VariantsAndLLM/. 

VaMoS continues with a bunch of presentations. I still argue that a key feature of VaMoS remains the discussant who must prepare slides to discuss the paper (summary of the understanding, applicability, future work, etc.) with the presenter. 15 minutes of presentation 15 minutes of discussions. You really get feedbacks! It is much better than some conferences where you traverse the Atlantic to have 1 out-of-the-scope, unprepared question. 

Among presentation, I really enjoyed a fascinating talk by Paul Grünbacher about variants and versions of... music artefacts. I loved the connection with other areas, the role of software, the DSLs, and the power of varying code in space and time. Some key slides: https://twitter.com/acherm/status/1755173588456374335
Paper is available online: https://dl.acm.org/doi/10.1145/3634713.3634723 

Another talk I appreciated was about StackOverflow and misconfiguration. The paper provides evidence that configuration is an important cause of software vulnerability. 
What strikes me after hearing the talk is that with the rise of generative AI, there will be two consequences: less content in StackOverflow... and config recommendations of generative AI that can be quickly deprecated due to the lack of data in... StackOverflow. 
It is an instance of a more general problem (generative AI will quickly miss high quality data), with dramatic consequences. 
Configuration of software will be very challenging in the future!  


Day-2 of VaMoS was nice as well. Maxime Cordy made a great keynote https://vamos2024.inf.unibe.ch/keynotes/scientific-keynote/ about machine learning and variability. 
The presentation of the 10-year Most Influential Paper Award "Towards Statistical Prioritization for Software Product Lines Testing" for my ex-Namur colleagues (Xavier Devroey, Gilles Perrrouin Maxime Cordy, Pierre-Yves Schobbens, Axel Legay and Patrick Heymans) was a great moment as well. There were even good words of Andrez Wasowski remotely. I also announced that VaMoS 2025 will be in Rennes. Stay tuned! 

The last day I've presented "A Demonstration of End-User Code Customization Using Generative AI" (preprint here: https://hal.science/hal-04312909, slides: https://www.slideshare.net/slideshows/a-demonstration-of-enduser-code-customization-using-generative-ai/266239123). 
I have not made a live demonstration, because Generative AI is still too stochastic for anticipating all possible failure demos that already happen with non-stochastic systems ;) 
But I've presented the key ideas and steps (feature identification and location, synthesize of template-based generators, development of Web configurators), applicable not only to TikZ code, but also to SVG, HTML, CSS, and JavaScript. 

![](/assets/WebTikZVariation.png)

I finished VaMoS with some slides to discuss the paper of Sandra Greiner, Klaus Schmid, Thorsten Berger, Sebastian Krieter and Kristof Meixner "Generative AI And Software Variability – A Research Vision" I did appreciate the proposed levels of Generative AI (GAI) when it comes to support software product line engineering (SPLE). These levels are related to automation, quality of output, input scale, and covering of SPLE tasks. Not that levels of GAI are different from levels of AGI https://arxiv.org/abs/2311.02462 as proposed by DeepMind for Artificial General Intelligence. I've tried to classify some papers about GAI and SPLE, including my own https://blog.mathieuacher.com/ChatGPTVariability/ and https://blog.mathieuacher.com/VariantsAndLLM/: it's interesting. Many challenges ahead!

VaMoS was a great conference, with nice social events. Thanks to Timo Kehrer, the general chair, the two PC Chairs, Marianne Huchard and Leopoldo Teixeira, the whole PC, and the "locals": Sandra Greiner, Bettina Choffat, Yael van Dok, Alexander Boll, Christian Birchler, etc. 
Looking forward VaMoS 2025, it is our time in Rennes (France)... stay tuned!


 



