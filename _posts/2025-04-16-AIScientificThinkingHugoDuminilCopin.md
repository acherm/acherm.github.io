---
layout: post
title:  "Creative Collaboration with AI: Insights from Hugo Duminil-Copin on Mathematics and Discovery"
date:   2025-04-16 11:54:29 +0200
tags: [AI, scientific thinking, discovery, creativity, mathematics]
---

I recently watched a great interview of the mathematician and Fields medalist (2022) Hugo Duminil-Copin by Science étonnante (aka David Louapre).
At some point, there was an interesting discussion on the role of AI in the discovery of new mathematical findings.
I think the arguments generalize far beyond mathematics: AI as a creative sparring partner, AI as a way to have an inner, interactive dialogue with oneself, AI as a tool to automate the boring parts of the process, human fallibility as a strength, the need for collaboration, etc. I share the transcript of the interview below and comment a bit.

You can [watch the talk on YouTube](https://www.youtube.com/watch?v=N_3FMrUUS6A) and jump around 26 minutes. It is in French, but you can certainly rely on subtitles.
The whole video is incredible, with an original interview format spanning different aspects of a mathematician, from early career and anecdotes to a more technical presentation over the board on percolation and Ising model.
Highly recommended!


The original question by [Science étonnante](https://www.youtube.com/scienceetonnante) aka David Louapre[^1] about AI:
```
A quick question about something that's getting a lot of attention these days: the contributions of artificial intelligence, and especially over the past two or three years, large language models. I was reading -- I think it was Terence Tao -- saying that we're not too far off from being able to use some large language models almost like, in quotes, a co-author. Not in the sense that it writes the paper for you, but more like a kind of creative sparring partner.
 Is that something you've tried?
```

Hugo Duminil-Copin confirms the use of AI and starts with a honest admission of its daily usage:
```
I have, yes. I use LLMs a lot as assistants, because -- and we don't talk about this much -- but a big part of our job is also admin work, writing, documentation. So it helps a lot in that regard.
```

It's kind of reassuring to know that a Fields medalist has the same habits as many mortals and scientists ;)

Then, Hugo Duminil-Copin answers more specifically:
```
On the mathematical level, it hasn't been useful yet, but **I have no doubt it will be soon**. One thing that's clear is that there are **different levels of innovation in papers**, in the solutions we produce, and you could say one way to look at it is: the biggest discoveries are essentially long-distance analogies between different things. And the further apart the analogy, the more fundamental the discovery.

It’s kind of like Einstein, for example -- his unified cosmic vision was really about drawing a deep analogy between things like gravity and electromagnetism. So major discoveries often work like that. And I think that’s the real challenge for artificial intelligence: being able to make those long-distance analogies. They'll probably get there one day, but today that’s still the hardest part.

On the other hand, once the big analogy has been made, it’s kind of like a fractal -- you’ve got a small tree with lots of little branches. You still have to do all the work to make the main idea function. And within that, there are even smaller things to figure out. And it’s clear that AI is going to become increasingly capable of helping us build those parts, even in mathematics.
It won’t just be about writing things up -- it'll be about contributing to the construction of the ideas. Like you were saying about architecture: maybe AI can't fully do the architectural planning yet, but it's starting to help with the actual building.
```

with basically two arguments: (1) AI as a tool to help scientists connect the dots and explore new ideas/concepts; (2) AI as a way to automate boring, low-level, langfruits, error-prone tasks.
I agree (1) is not there yet. In fact, it's a bit mysterious why LLMs haven't been able to find such connections, owing to the large amount of data available to train them.
But when it will be the case, it will be for sure a revolution.
For (2), I am also seeing a connection with software engineering, where the hardest part is not the pure coding itself, but the design and architecture of the system (among others).

Hugo Duminil-Copin then continues:
```
Another thing that's true is that the creative process in mathematics, like in many other fields, is based on **internal dialogue**: trying ideas, realizing they don't work, understanding why they don’t work, and using that information to try something new that will also probably fail -- until, eventually, something clicks.

So this inner dialogue -- or a small group dialogue with other mathematicians -- is crucial. Having an AI to bounce ideas off of can absolutely bring something to the table. Any additional information is helpful, so I have no doubt it will soon become truly useful—if only for quickly flagging something that's clearly wrong.
```

Really enjoy this part, as it matches my own experience and I guess of many others.

Hugo Duminil-Copin concludes with a more personal perspective on the creative process in mathematics:
```
It's funny, we all have our little quirks. For example, I'm someone who makes a lot of **approximate mistakes**. I have a really bad memory, and weirdly, that actually helps me a lot. Because I approximate everything. I’ll say, “Oh, this paper has exactly what we need,” then I go check it, and it turns out it’s not at all what the paper was doing. But the version I had in my head, even if it’s very imprecise, still works in a way.

You can end up using ideas from the paper for something quite different than originally intended, just because you misremembered it -- but the misremembered version is still interesting. So in a way, my bad memory is actually kind of a strength.

But because of that, I really need people around me -- collaborators. I often work with people who have a more precise, sharp way of thinking. I'm thinking of [Ioan Manolescu](https://homeweb.unifr.ch/manolesc/Pub/), one of my closest collaborators and a very dear friend. He's great at telling me when I'm completely wrong, which happens often, and from there we can bounce back and find something that actually works.

That's a skill I don't really have. So when Mano is not around, maybe I need something else. And likewise, for him, maybe there are things he is not as strong at, and an AI that can suggest ideas would definitely be helpful. No doubt about it.
```

I really enjoy the recognition of approximating ideas and making mistakes as a feature of the scientific process. LLMs could be good collaborators here.
And we need a diversity of collaborators ;)

Overall, Hugo Duminil-Copin is quite optimistic about the use of AI.
What I find most compelling is the idea of AI helping not by being perfect, but by engaging with our imperfections -- amplifying our approximations, filling gaps in our ideas, memory or inner-dialogue, and offering potential for the creative process, either through automation of low-level tasks or identification of long analogies.
Not there yet, but I am definitely in.
In fact, my current and future research will be about AI and sofware engineering for reproducible and replicable science. More to come soon ;)

[^1]: you can find some "traces" of David in this work about... chess and LLM: https://github.com/acherm/gptchess/blob/main/analysis_prompt_variations.ipynb
side note: The original transcript is available in a gist (in French, slightly edited out of OpenAI whisper)
